{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üå∂Ô∏è Bell Pepper Detection with YOLOv8\n",
        "\n",
        "This notebook trains a specialized YOLOv8 model for bell pepper detection and quality assessment.\n",
        "\n",
        "## üìã Steps Overview:\n",
        "1. **Setup Environment** - Install dependencies\n",
        "2. **Upload Dataset** - Upload your YOLO dataset\n",
        "3. **Configure Training** - Set training parameters\n",
        "4. **Train Model** - Train YOLOv8 on bell pepper data\n",
        "5. **Validate Results** - Test and evaluate the model\n",
        "6. **Export Model** - Download trained model for production\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Step 1: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install ultralytics\n",
        "%pip install roboflow\n",
        "%pip install wandb  # For experiment tracking (optional)\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Training will be slower on CPU.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Step 2: Download Dataset from Google Drive\n",
        "\n",
        "Since you've uploaded your dataset to Google Drive, we'll download it directly to Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset from Google Drive\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Your Google Drive file ID\n",
        "file_id = \"1PZYraaZ4q-G_N0fQz_GXlD8nNvdOoFNJ\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "print(\"üì• Downloading Bell Pepper YOLO Dataset from Google Drive...\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Download the ZIP file\n",
        "gdown.download(url, \"bell_pepper_yolo_dataset.zip\", quiet=False)\n",
        "\n",
        "# Extract the dataset\n",
        "print(\"\\nüìÇ Extracting dataset...\")\n",
        "with zipfile.ZipFile(\"bell_pepper_yolo_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# Clean up ZIP file\n",
        "os.remove(\"bell_pepper_yolo_dataset.zip\")\n",
        "\n",
        "print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n",
        "\n",
        "# Find the dataset directory (it might be nested)\n",
        "dataset_path = None\n",
        "possible_paths = [\"yolo_dataset\", \"dataset\", \"bell_pepper_dataset\"]\n",
        "\n",
        "# Check current directory for extracted files\n",
        "extracted_items = [item for item in os.listdir(\".\") if os.path.isdir(item)]\n",
        "print(f\"\\nüìÅ Extracted directories: {extracted_items}\")\n",
        "\n",
        "# Look for the dataset directory\n",
        "for item in extracted_items:\n",
        "    item_path = Path(item)\n",
        "    # Check if this directory contains the expected YOLO structure\n",
        "    if (item_path / \"images\").exists() or (item_path / \"dataset.yaml\").exists():\n",
        "        dataset_path = str(item_path)\n",
        "        print(f\"‚úÖ Found dataset directory: {dataset_path}\")\n",
        "        break\n",
        "\n",
        "# If not found in direct subdirectories, look deeper\n",
        "if dataset_path is None:\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if \"dataset.yaml\" in files:\n",
        "            dataset_path = root\n",
        "            print(f\"‚úÖ Found dataset directory: {dataset_path}\")\n",
        "            break\n",
        "\n",
        "if dataset_path is None:\n",
        "    print(\"‚ùå Dataset directory not found! Let's explore the structure...\")\n",
        "    # Show all extracted contents\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if root != \".\":  # Skip current directory\n",
        "            level = root.count(os.sep) - 1\n",
        "            indent = \" \" * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = \" \" * 2 * (level + 1)\n",
        "            for file in files[:5]:  # Show first 5 files\n",
        "                print(f\"{subindent}{file}\")\n",
        "            if len(files) > 5:\n",
        "                print(f\"{subindent}... and {len(files) - 5} more files\")\n",
        "else:\n",
        "    # Show the found dataset structure\n",
        "    print(f\"\\nüìÅ Dataset structure in {dataset_path}:\")\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        level = root.replace(dataset_path, \"\").count(os.sep)\n",
        "        indent = \" \" * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = \" \" * 2 * (level + 1)\n",
        "        for file in files[:3]:  # Show first 3 files\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"{subindent}... and {len(files) - 3} more files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify dataset structure and preview samples\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import yaml\n",
        "\n",
        "def verify_dataset_structure(dataset_path):\n",
        "    \"\"\"Verify the dataset has correct YOLO structure\"\"\"\n",
        "    if dataset_path is None:\n",
        "        print(\"‚ùå No dataset path provided!\")\n",
        "        return None, False\n",
        "        \n",
        "    dataset_path = Path(dataset_path)\n",
        "    \n",
        "    required_dirs = [\n",
        "        'images/train', 'images/val',\n",
        "        'labels/train', 'labels/val'\n",
        "    ]\n",
        "    \n",
        "    print(\"üîç Dataset Structure Verification:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    all_good = True\n",
        "    for dir_name in required_dirs:\n",
        "        dir_path = dataset_path / dir_name\n",
        "        if dir_path.exists():\n",
        "            file_count = len(list(dir_path.glob('*')))\n",
        "            print(f\"‚úÖ {dir_name}: {file_count} files\")\n",
        "        else:\n",
        "            print(f\"‚ùå {dir_name}: Missing!\")\n",
        "            all_good = False\n",
        "    \n",
        "    # Check for dataset.yaml\n",
        "    yaml_path = dataset_path / 'dataset.yaml'\n",
        "    if yaml_path.exists():\n",
        "        print(f\"‚úÖ dataset.yaml: Found\")\n",
        "        \n",
        "        # Load and display dataset config\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config = yaml.safe_load(f)\n",
        "        \n",
        "        print(f\"\\nüìä Dataset Configuration:\")\n",
        "        print(f\"   Classes: {config.get('nc', 'Unknown')}\")\n",
        "        print(f\"   Class names: {config.get('names', 'Unknown')}\")\n",
        "        print(f\"   Train images: {config.get('train_images', 'Unknown')}\")\n",
        "        print(f\"   Val images: {config.get('val_images', 'Unknown')}\")\n",
        "        \n",
        "        return config, all_good\n",
        "        \n",
        "    else:\n",
        "        print(f\"‚ùå dataset.yaml: Missing!\")\n",
        "        all_good = False\n",
        "    \n",
        "    if all_good:\n",
        "        print(\"\\nüéâ Dataset structure is correct!\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Dataset structure issues detected. Please fix before training.\")\n",
        "    \n",
        "    return None, all_good\n",
        "\n",
        "# Verify the dataset using the found path\n",
        "if 'dataset_path' in locals() and dataset_path is not None:\n",
        "    config, dataset_valid = verify_dataset_structure(dataset_path)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dataset path not found. Please run the previous cell first.\")\n",
        "    config, dataset_valid = None, False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix dataset structure if needed\n",
        "if not dataset_valid and dataset_path is not None:\n",
        "    print(\"üîß Attempting to fix dataset structure...\")\n",
        "    \n",
        "    # Sometimes the dataset might be in a subdirectory or have different structure\n",
        "    # Let's look for images and labels directories\n",
        "    dataset_root = Path(dataset_path)\n",
        "    \n",
        "    # Find images and labels directories\n",
        "    images_dirs = list(dataset_root.rglob(\"images\"))\n",
        "    labels_dirs = list(dataset_root.rglob(\"labels\"))\n",
        "    yaml_files = list(dataset_root.rglob(\"*.yaml\"))\n",
        "    \n",
        "    print(f\"Found images directories: {[str(d) for d in images_dirs]}\")\n",
        "    print(f\"Found labels directories: {[str(d) for d in labels_dirs]}\")\n",
        "    print(f\"Found YAML files: {[str(f) for f in yaml_files]}\")\n",
        "    \n",
        "    # If we found the structure but it's nested, update the dataset_path\n",
        "    if images_dirs and labels_dirs:\n",
        "        # Find the common parent directory\n",
        "        common_parent = images_dirs[0].parent\n",
        "        if (common_parent / \"images\").exists() and (common_parent / \"labels\").exists():\n",
        "            dataset_path = str(common_parent)\n",
        "            print(f\"üîÑ Updated dataset path to: {dataset_path}\")\n",
        "            \n",
        "            # Re-verify with the new path\n",
        "            config, dataset_valid = verify_dataset_structure(dataset_path)\n",
        "    \n",
        "    # If still not valid, try to create a proper structure\n",
        "    if not dataset_valid:\n",
        "        print(\"üî® Attempting to restructure dataset...\")\n",
        "        \n",
        "        # Create a new properly structured dataset\n",
        "        new_dataset_path = \"bell_pepper_yolo_dataset\"\n",
        "        new_dataset = Path(new_dataset_path)\n",
        "        \n",
        "        # Create directories\n",
        "        (new_dataset / \"images\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "        (new_dataset / \"images\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "        (new_dataset / \"labels\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "        (new_dataset / \"labels\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # If we have any YAML files, copy the first one\n",
        "        if yaml_files:\n",
        "            import shutil\n",
        "            shutil.copy2(yaml_files[0], new_dataset / \"dataset.yaml\")\n",
        "            print(f\"‚úÖ Copied dataset configuration: {yaml_files[0].name}\")\n",
        "        \n",
        "        # Try to move/copy files if we can find them\n",
        "        all_images = list(Path(dataset_path).rglob(\"*.jpg\")) + list(Path(dataset_path).rglob(\"*.png\"))\n",
        "        all_labels = list(Path(dataset_path).rglob(\"*.txt\"))\n",
        "        \n",
        "        if all_images:\n",
        "            print(f\"Found {len(all_images)} image files\")\n",
        "            # For now, put everything in train (you can split later)\n",
        "            train_dir = new_dataset / \"images\" / \"train\"\n",
        "            for img in all_images[:10]:  # Copy first 10 as example\n",
        "                shutil.copy2(img, train_dir / img.name)\n",
        "        \n",
        "        if all_labels and len(all_labels) > 1:  # More than just dataset.yaml\n",
        "            print(f\"Found {len(all_labels)} label files\")\n",
        "            train_labels_dir = new_dataset / \"labels\" / \"train\"\n",
        "            for lbl in all_labels[:10]:  # Copy first 10 as example\n",
        "                if lbl.name != \"dataset.yaml\":\n",
        "                    shutil.copy2(lbl, train_labels_dir / lbl.name)\n",
        "        \n",
        "        # Update dataset path\n",
        "        dataset_path = new_dataset_path\n",
        "        print(f\"üîÑ Created new dataset structure at: {dataset_path}\")\n",
        "        \n",
        "        # Re-verify\n",
        "        config, dataset_valid = verify_dataset_structure(dataset_path)\n",
        "\n",
        "if dataset_valid:\n",
        "    print(\"üéâ Dataset is now ready for training!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dataset structure still needs manual fixing.\")\n",
        "    print(\"Please check the extracted files and ensure proper YOLO format.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview sample images with annotations\n",
        "def preview_samples(dataset_path, num_samples=4):\n",
        "    \"\"\"Preview sample images with their annotations\"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    \n",
        "    # Get sample images from training set\n",
        "    train_images = list((dataset_path / 'images' / 'train').glob('*'))\n",
        "    sample_images = train_images[:num_samples]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Load class names from config\n",
        "    class_names = config['names'] if config else [f'bell_pepper_{i}' for i in range(6)]\n",
        "    \n",
        "    for i, img_path in enumerate(sample_images):\n",
        "        if i >= 4:\n",
        "            break\n",
        "            \n",
        "        # Load image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        height, width = img.shape[:2]\n",
        "        \n",
        "        # Load corresponding label file\n",
        "        label_path = dataset_path / 'labels' / 'train' / f\"{img_path.stem}.txt\"\n",
        "        \n",
        "        ax = axes[i]\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"Sample {i+1}: {img_path.name}\", fontsize=10)\n",
        "        ax.axis('off')\n",
        "        \n",
        "        # Draw bounding boxes if label file exists\n",
        "        bbox_count = 0\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            \n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id, x_center, y_center, bbox_width, bbox_height = map(float, parts)\n",
        "                    \n",
        "                    # Convert YOLO format to pixel coordinates\n",
        "                    x_center *= width\n",
        "                    y_center *= height\n",
        "                    bbox_width *= width\n",
        "                    bbox_height *= height\n",
        "                    \n",
        "                    # Calculate top-left corner\n",
        "                    x = x_center - bbox_width / 2\n",
        "                    y = y_center - bbox_height / 2\n",
        "                    \n",
        "                    # Draw bounding box\n",
        "                    rect = patches.Rectangle((x, y), bbox_width, bbox_height, \n",
        "                                           linewidth=2, edgecolor='red', facecolor='none')\n",
        "                    ax.add_patch(rect)\n",
        "                    \n",
        "                    # Add class label\n",
        "                    class_name = class_names[int(class_id)] if int(class_id) < len(class_names) else f\"Class {int(class_id)}\"\n",
        "                    ax.text(x, y-5, class_name, color='red', fontsize=8, \n",
        "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "                    bbox_count += 1\n",
        "        \n",
        "        # Add bbox count to title\n",
        "        ax.set_title(f\"Sample {i+1} ({bbox_count} peppers): {img_path.name}\", fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if dataset_valid and config:\n",
        "    print(\"üñºÔ∏è Sample Images with Annotations:\")\n",
        "    preview_samples(dataset_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Step 3: Configure Training Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration optimized for your dataset\n",
        "TRAINING_CONFIG = {\n",
        "    # Model settings - Using nano model for faster training with limited specs\n",
        "    'model_size': 'yolov8n.pt',  # Options: yolov8n.pt, yolov8s.pt, yolov8m.pt\n",
        "    \n",
        "    # Training parameters optimized for your 620 image dataset\n",
        "    'epochs': 150,              # Good for your dataset size\n",
        "    'batch_size': 16,           # Will adjust based on GPU memory\n",
        "    'img_size': 640,            # Standard YOLO input size\n",
        "    'lr': 0.01,                 # Learning rate\n",
        "    'patience': 50,             # Early stopping patience\n",
        "    \n",
        "    # Data augmentation for bell peppers\n",
        "    'augment': True,            # Enable data augmentation\n",
        "    'hsv_h': 0.015,            # HSV-Hue augmentation (good for color varieties)\n",
        "    'hsv_s': 0.7,              # HSV-Saturation augmentation  \n",
        "    'hsv_v': 0.4,              # HSV-Value augmentation\n",
        "    'degrees': 10.0,           # Small rotation (peppers can be oriented differently)\n",
        "    'translate': 0.1,          # Translation\n",
        "    'scale': 0.5,              # Scale variation\n",
        "    'shear': 0.0,              # No shear (keeps pepper shape)\n",
        "    'perspective': 0.0,        # No perspective (keeps pepper shape)\n",
        "    'flipud': 0.0,             # No vertical flip (peppers hang down)\n",
        "    'fliplr': 0.5,             # Horizontal flip (peppers can be on either side)\n",
        "    'mosaic': 1.0,             # Mosaic augmentation (great for detection)\n",
        "    'mixup': 0.0,              # No mixup for better bounding box learning\n",
        "    \n",
        "    # Output settings\n",
        "    'project': 'bell_pepper_training',  # Project name\n",
        "    'name': 'yolov8_bell_pepper_v1',    # Experiment name\n",
        "    'save_period': 25,                  # Save checkpoint every 25 epochs\n",
        "}\n",
        "\n",
        "print(\"üîß Training Configuration for Bell Pepper Detection:\")\n",
        "print(\"=\" * 55)\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"{key:20}: {value}\")\n",
        "\n",
        "# Adjust batch size based on available GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB\n",
        "    print(f\"\\nüíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
        "    \n",
        "    if gpu_memory < 6:\n",
        "        TRAINING_CONFIG['batch_size'] = 8\n",
        "        print(\"‚ö†Ô∏è Reduced batch size to 8 due to limited GPU memory\")\n",
        "    elif gpu_memory < 4:\n",
        "        TRAINING_CONFIG['batch_size'] = 4\n",
        "        print(\"‚ö†Ô∏è Reduced batch size to 4 due to very limited GPU memory\")\n",
        "    elif gpu_memory > 12:\n",
        "        TRAINING_CONFIG['batch_size'] = 32\n",
        "        print(\"üöÄ Increased batch size to 32 for better training speed\")\n",
        "else:\n",
        "    TRAINING_CONFIG['batch_size'] = 4\n",
        "    TRAINING_CONFIG['epochs'] = 100\n",
        "    print(\"‚ö†Ô∏è CPU training detected - reduced batch size and epochs\")\n",
        "\n",
        "print(f\"\\nüéØ Final batch size: {TRAINING_CONFIG['batch_size']}\")\n",
        "\n",
        "# Only print dataset info if config is available\n",
        "if config is not None:\n",
        "    print(f\"üìä Dataset: {config.get('train_images', 'Unknown')} train, {config.get('val_images', 'Unknown')} val images\")\n",
        "    print(f\"üè∑Ô∏è Classes: {config.get('nc', 'Unknown')} bell pepper varieties\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dataset configuration not loaded. Please verify dataset structure first.\")\n",
        "    print(\"üìä Dataset: Configuration pending...\")\n",
        "    print(\"üè∑Ô∏è Classes: Will be determined after dataset verification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix dataset.yaml paths before training\n",
        "print(\"üîß Fixing dataset.yaml paths for training...\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if dataset_path is None:\n",
        "    print(\"‚ùå Dataset path not found. Please run the previous cells first.\")\n",
        "else:\n",
        "    # Load the current dataset.yaml\n",
        "    yaml_path = Path(dataset_path) / 'dataset.yaml'\n",
        "    \n",
        "    if yaml_path.exists():\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            dataset_config = yaml.safe_load(f)\n",
        "        \n",
        "        # Get absolute path to dataset directory\n",
        "        current_dataset_path = Path(dataset_path).absolute()\n",
        "        \n",
        "        # Create corrected dataset.yaml with absolute paths\n",
        "        corrected_config = {\n",
        "            'path': str(current_dataset_path),  # Dataset root dir (absolute path)\n",
        "            'train': 'images/train',  # Train images (relative to 'path')\n",
        "            'val': 'images/val',      # Val images (relative to 'path')\n",
        "            'nc': dataset_config.get('nc', 6),  # Number of classes\n",
        "            'names': dataset_config.get('names', [f'bell_pepper_{i+1}' for i in range(6)]),  # Class names\n",
        "        }\n",
        "        \n",
        "        # Write corrected dataset.yaml\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(corrected_config, f, default_flow_style=False)\n",
        "        \n",
        "        print(f\"‚úÖ Updated dataset.yaml with correct paths:\")\n",
        "        print(f\"   Path: {corrected_config['path']}\")\n",
        "        print(f\"   Train: {corrected_config['train']}\")\n",
        "        print(f\"   Val: {corrected_config['val']}\")\n",
        "        print(f\"   Classes: {corrected_config['nc']}\")\n",
        "        print(f\"   Names: {corrected_config['names']}\")\n",
        "        \n",
        "        # Verify the paths exist\n",
        "        train_path = current_dataset_path / 'images' / 'train'\n",
        "        val_path = current_dataset_path / 'images' / 'val'\n",
        "        train_labels_path = current_dataset_path / 'labels' / 'train'\n",
        "        val_labels_path = current_dataset_path / 'labels' / 'val'\n",
        "        \n",
        "        train_images = len(list(train_path.glob('*'))) if train_path.exists() else 0\n",
        "        val_images = len(list(val_path.glob('*'))) if val_path.exists() else 0\n",
        "        train_labels = len(list(train_labels_path.glob('*.txt'))) if train_labels_path.exists() else 0\n",
        "        val_labels = len(list(val_labels_path.glob('*.txt'))) if val_labels_path.exists() else 0\n",
        "        \n",
        "        print(f\"\\nüìä Dataset Statistics:\")\n",
        "        print(f\"   Train images: {train_images}\")\n",
        "        print(f\"   Train labels: {train_labels}\")\n",
        "        print(f\"   Val images: {val_images}\")\n",
        "        print(f\"   Val labels: {val_labels}\")\n",
        "        \n",
        "        # Check if paths are valid\n",
        "        if train_images == 0 or val_images == 0:\n",
        "            print(\"\\n‚ö†Ô∏è Warning: Some image directories are empty!\")\n",
        "            print(\"Searching for images in dataset...\")\n",
        "            \n",
        "            # Find all images in the dataset\n",
        "            all_images = list(current_dataset_path.rglob(\"*.jpg\")) + list(current_dataset_path.rglob(\"*.png\"))\n",
        "            all_labels = list(current_dataset_path.rglob(\"*.txt\"))\n",
        "            \n",
        "            print(f\"Total images found: {len(all_images)}\")\n",
        "            print(f\"Total txt files found: {len(all_labels)}\")\n",
        "            \n",
        "            if len(all_images) > 0:\n",
        "                print(\"\\nüìÅ Image file locations (first 5):\")\n",
        "                for img in all_images[:5]:\n",
        "                    rel_path = img.relative_to(current_dataset_path)\n",
        "                    print(f\"   {rel_path}\")\n",
        "                \n",
        "                # Try to organize files if needed\n",
        "                if train_images == 0 and len(all_images) > 0:\n",
        "                    print(\"\\nüî® Attempting to organize dataset...\")\n",
        "                    \n",
        "                    # Create directories if they don't exist\n",
        "                    train_path.mkdir(parents=True, exist_ok=True)\n",
        "                    val_path.mkdir(parents=True, exist_ok=True)\n",
        "                    train_labels_path.mkdir(parents=True, exist_ok=True)\n",
        "                    val_labels_path.mkdir(parents=True, exist_ok=True)\n",
        "                    \n",
        "                    # Move images to train/val (80/20 split)\n",
        "                    import shutil\n",
        "                    import random\n",
        "                    \n",
        "                    random.shuffle(all_images)\n",
        "                    split_idx = int(0.8 * len(all_images))\n",
        "                    \n",
        "                    train_imgs = all_images[:split_idx]\n",
        "                    val_imgs = all_images[split_idx:]\n",
        "                    \n",
        "                    # Copy images\n",
        "                    for img in train_imgs:\n",
        "                        shutil.copy2(img, train_path / img.name)\n",
        "                    \n",
        "                    for img in val_imgs:\n",
        "                        shutil.copy2(img, val_path / img.name)\n",
        "                    \n",
        "                    # Copy corresponding labels\n",
        "                    for img in train_imgs:\n",
        "                        label_name = img.stem + '.txt'\n",
        "                        for label_file in all_labels:\n",
        "                            if label_file.name == label_name:\n",
        "                                shutil.copy2(label_file, train_labels_path / label_name)\n",
        "                                break\n",
        "                    \n",
        "                    for img in val_imgs:\n",
        "                        label_name = img.stem + '.txt'\n",
        "                        for label_file in all_labels:\n",
        "                            if label_file.name == label_name:\n",
        "                                shutil.copy2(label_file, val_labels_path / label_name)\n",
        "                                break\n",
        "                    \n",
        "                    print(f\"‚úÖ Organized dataset:\")\n",
        "                    print(f\"   Moved {len(train_imgs)} images to train\")\n",
        "                    print(f\"   Moved {len(val_imgs)} images to val\")\n",
        "        \n",
        "        print(f\"\\nüéØ Dataset ready for training!\")\n",
        "        print(f\"üìÑ Using dataset config: {yaml_path}\")\n",
        "        \n",
        "    else:\n",
        "        print(f\"‚ùå dataset.yaml not found at {yaml_path}\")\n",
        "        print(\"Creating a basic dataset.yaml file...\")\n",
        "        \n",
        "        # Create a basic dataset.yaml\n",
        "        basic_config = {\n",
        "            'path': str(Path(dataset_path).absolute()),\n",
        "            'train': 'images/train',\n",
        "            'val': 'images/val',\n",
        "            'nc': 6,\n",
        "            'names': [f'bell_pepper_{i+1}' for i in range(6)]\n",
        "        }\n",
        "        \n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(basic_config, f, default_flow_style=False)\n",
        "        \n",
        "        print(f\"‚úÖ Created basic dataset.yaml at {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 4: Train the Bell Pepper Detection Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the bell pepper detection model\n",
        "print(\"üöÄ Starting Bell Pepper YOLOv8 Training...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load the base model\n",
        "model = YOLO(TRAINING_CONFIG['model_size'])\n",
        "\n",
        "# Print model info\n",
        "print(f\"üì± Model: {TRAINING_CONFIG['model_size']}\")\n",
        "print(f\"üî¢ Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
        "print(f\"üìä Dataset: {config['nc']} classes, {config['train_images']} train images\")\n",
        "print(f\"‚öôÔ∏è Batch size: {TRAINING_CONFIG['batch_size']}, Epochs: {TRAINING_CONFIG['epochs']}\")\n",
        "\n",
        "print(\"\\nüé¨ Starting training process...\")\n",
        "print(\"This may take 30-60 minutes depending on your GPU...\")\n",
        "\n",
        "# Start training with optimized settings for bell peppers\n",
        "results = model.train(\n",
        "    data=f\"{dataset_path}/dataset.yaml\",\n",
        "    epochs=TRAINING_CONFIG['epochs'],\n",
        "    batch=TRAINING_CONFIG['batch_size'],\n",
        "    imgsz=TRAINING_CONFIG['img_size'],\n",
        "    lr0=TRAINING_CONFIG['lr'],\n",
        "    patience=TRAINING_CONFIG['patience'],\n",
        "    \n",
        "    # Data augmentation optimized for bell peppers\n",
        "    augment=TRAINING_CONFIG['augment'],\n",
        "    hsv_h=TRAINING_CONFIG['hsv_h'],\n",
        "    hsv_s=TRAINING_CONFIG['hsv_s'],\n",
        "    hsv_v=TRAINING_CONFIG['hsv_v'],\n",
        "    degrees=TRAINING_CONFIG['degrees'],\n",
        "    translate=TRAINING_CONFIG['translate'],\n",
        "    scale=TRAINING_CONFIG['scale'],\n",
        "    shear=TRAINING_CONFIG['shear'],\n",
        "    perspective=TRAINING_CONFIG['perspective'],\n",
        "    flipud=TRAINING_CONFIG['flipud'],\n",
        "    fliplr=TRAINING_CONFIG['fliplr'],\n",
        "    mosaic=TRAINING_CONFIG['mosaic'],\n",
        "    mixup=TRAINING_CONFIG['mixup'],\n",
        "    \n",
        "    # Output settings\n",
        "    project=TRAINING_CONFIG['project'],\n",
        "    name=TRAINING_CONFIG['name'],\n",
        "    save_period=TRAINING_CONFIG['save_period'],\n",
        "    \n",
        "    # Additional settings for optimal training\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    workers=4,\n",
        "    verbose=True,\n",
        "    seed=42,  # For reproducible results\n",
        "    optimizer='AdamW',  # Good optimizer for small datasets\n",
        "    close_mosaic=10,    # Disable mosaic in last 10 epochs for better accuracy\n",
        ")\n",
        "\n",
        "print(\"\\nüéâ Training completed successfully!\")\n",
        "print(\"üìÅ Training results and model weights have been saved.\")\n",
        "\n",
        "# Display training summary\n",
        "if hasattr(results, 'results_dict'):\n",
        "    print(f\"\\nüìä Final Training Metrics:\")\n",
        "    metrics = results.results_dict\n",
        "    if 'metrics/mAP50(B)' in metrics:\n",
        "        print(f\"   mAP@0.5: {metrics['metrics/mAP50(B)']:.3f}\")\n",
        "    if 'metrics/mAP50-95(B)' in metrics:\n",
        "        print(f\"   mAP@0.5:0.95: {metrics['metrics/mAP50-95(B)']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 5: Analyze Training Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find and display training results\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "\n",
        "# Find the latest training run directory\n",
        "project_dir = Path(TRAINING_CONFIG['project'])\n",
        "latest_run = max(project_dir.glob(f\"{TRAINING_CONFIG['name']}*\"), key=os.path.getctime)\n",
        "\n",
        "print(f\"üìÅ Training results saved in: {latest_run}\")\n",
        "print(f\"üéØ Model files location: {latest_run}/weights/\")\n",
        "\n",
        "# Display training curves\n",
        "results_img = latest_run / 'results.png'\n",
        "if results_img.exists():\n",
        "    print(\"\\nüìà Training Results and Loss Curves:\")\n",
        "    display(Image(str(results_img), width=800))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Results image not found\")\n",
        "\n",
        "# Display confusion matrix\n",
        "confusion_matrix = latest_run / 'confusion_matrix.png'\n",
        "if confusion_matrix.exists():\n",
        "    print(\"\\nüîç Confusion Matrix:\")\n",
        "    display(Image(str(confusion_matrix), width=600))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Confusion matrix not found\")\n",
        "\n",
        "# Display F1 confidence curve\n",
        "f1_curve = latest_run / 'F1_curve.png'\n",
        "if f1_curve.exists():\n",
        "    print(\"\\nüìä F1-Confidence Curve:\")\n",
        "    display(Image(str(f1_curve), width=600))\n",
        "\n",
        "# Display precision-recall curve\n",
        "pr_curve = latest_run / 'PR_curve.png'\n",
        "if pr_curve.exists():\n",
        "    print(\"\\nüìä Precision-Recall Curve:\")\n",
        "    display(Image(str(pr_curve), width=600))\n",
        "\n",
        "# Display validation batch predictions\n",
        "val_batch = latest_run / 'val_batch0_pred.jpg'\n",
        "if val_batch.exists():\n",
        "    print(\"\\nüéØ Model Predictions on Validation Images:\")\n",
        "    display(Image(str(val_batch), width=800))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Validation predictions not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the trained model and evaluate performance\n",
        "import random\n",
        "\n",
        "# Load the best trained model\n",
        "best_model_path = latest_run / 'weights' / 'best.pt'\n",
        "trained_model = YOLO(str(best_model_path))\n",
        "\n",
        "print(f\"üß† Loaded best trained model: {best_model_path}\")\n",
        "\n",
        "# Validate the model on the validation set\n",
        "print(\"\\nüìä Running Model Validation...\")\n",
        "val_results = trained_model.val(data=f\"{dataset_path}/dataset.yaml\")\n",
        "\n",
        "# Print detailed performance metrics\n",
        "print(f\"\\nüéØ Bell Pepper Detection Performance:\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"mAP@0.5     : {val_results.box.map50:.3f} ({val_results.box.map50*100:.1f}%)\")\n",
        "print(f\"mAP@0.5:0.95: {val_results.box.map:.3f} ({val_results.box.map*100:.1f}%)\")\n",
        "print(f\"Precision   : {val_results.box.mp:.3f} ({val_results.box.mp*100:.1f}%)\")\n",
        "print(f\"Recall      : {val_results.box.mr:.3f} ({val_results.box.mr*100:.1f}%)\")\n",
        "\n",
        "# Performance interpretation\n",
        "map50 = val_results.box.map50\n",
        "if map50 > 0.9:\n",
        "    performance = \"üåü Excellent - Ready for production!\"\n",
        "    recommendation = \"Your model is performing exceptionally well!\"\n",
        "elif map50 > 0.8:\n",
        "    performance = \"üéâ Very Good - Great for most applications\"\n",
        "    recommendation = \"Excellent results! Consider testing on real-world data.\"\n",
        "elif map50 > 0.7:\n",
        "    performance = \"üëç Good - Suitable for many use cases\"\n",
        "    recommendation = \"Good performance. Fine-tune confidence threshold as needed.\"\n",
        "elif map50 > 0.6:\n",
        "    performance = \"‚ö†Ô∏è Fair - May need improvement\"\n",
        "    recommendation = \"Consider training longer or adding more diverse data.\"\n",
        "else:\n",
        "    performance = \"‚ùå Needs Improvement\"\n",
        "    recommendation = \"Try training with more epochs, better data, or larger model.\"\n",
        "\n",
        "print(f\"\\nOverall Performance: {performance}\")\n",
        "print(f\"Recommendation: {recommendation}\")\n",
        "\n",
        "# Calculate additional metrics\n",
        "total_params = sum(p.numel() for p in trained_model.model.parameters())\n",
        "model_size_mb = os.path.getsize(best_model_path) / (1024 * 1024)\n",
        "\n",
        "print(f\"\\nüì± Model Specifications:\")\n",
        "print(f\"   Parameters: {total_params:,}\")\n",
        "print(f\"   Model size: {model_size_mb:.1f} MB\")\n",
        "print(f\"   Classes: {val_results.names}\")\n",
        "\n",
        "# Class-wise performance if available\n",
        "if hasattr(val_results.box, 'ap_class_index') and val_results.box.ap_class_index is not None:\n",
        "    print(f\"\\nüìä Per-Class Performance (mAP@0.5):\")\n",
        "    for i, class_name in enumerate(val_results.names):\n",
        "        if i < len(val_results.box.ap):\n",
        "            class_map = val_results.box.ap[i].mean()  # Average across IoU thresholds\n",
        "            print(f\"   {class_name}: {class_map:.3f} ({class_map*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test model on sample validation images\n",
        "val_images = list((Path(dataset_path) / 'images' / 'val').glob('*'))\n",
        "test_images = random.sample(val_images, min(6, len(val_images)))\n",
        "\n",
        "print(\"üîÆ Model Predictions on Sample Validation Images:\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "detection_summary = []\n",
        "\n",
        "for i, img_path in enumerate(test_images):\n",
        "    if i >= 6:\n",
        "        break\n",
        "    \n",
        "    # Run inference\n",
        "    results = trained_model(str(img_path), conf=0.25)  # Lower confidence for more detections\n",
        "    result = results[0]\n",
        "    \n",
        "    # Plot the result\n",
        "    annotated_img = result.plot()\n",
        "    \n",
        "    ax = axes[i]\n",
        "    ax.imshow(annotated_img)\n",
        "    ax.set_title(f\"Test {i+1}: {img_path.name}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # Count detections by class\n",
        "    detections_count = {}\n",
        "    if result.boxes is not None:\n",
        "        for box in result.boxes:\n",
        "            conf = float(box.conf.cpu().numpy()[0])\n",
        "            cls = int(box.cls.cpu().numpy()[0])\n",
        "            class_name = result.names[cls]\n",
        "            \n",
        "            if class_name not in detections_count:\n",
        "                detections_count[class_name] = 0\n",
        "            detections_count[class_name] += 1\n",
        "        \n",
        "        detection_summary.append({\n",
        "            'image': img_path.name,\n",
        "            'total_detections': len(result.boxes),\n",
        "            'detections': detections_count\n",
        "        })\n",
        "        \n",
        "        # Add detection count to title\n",
        "        total_dets = len(result.boxes)\n",
        "        ax.set_title(f\"Test {i+1} ({total_dets} peppers): {img_path.name}\", fontsize=10)\n",
        "    else:\n",
        "        detection_summary.append({\n",
        "            'image': img_path.name,\n",
        "            'total_detections': 0,\n",
        "            'detections': {}\n",
        "        })\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detection summary\n",
        "print(\"\\nüìã Detection Summary:\")\n",
        "total_detected = 0\n",
        "class_totals = {}\n",
        "\n",
        "for summary in detection_summary:\n",
        "    img_name = summary['image']\n",
        "    total_dets = summary['total_detections']\n",
        "    total_detected += total_dets\n",
        "    \n",
        "    print(f\"\\nüì∏ {img_name}: {total_dets} bell pepper(s) detected\")\n",
        "    \n",
        "    for class_name, count in summary['detections'].items():\n",
        "        print(f\"   - {class_name}: {count}\")\n",
        "        if class_name not in class_totals:\n",
        "            class_totals[class_name] = 0\n",
        "        class_totals[class_name] += count\n",
        "\n",
        "print(f\"\\nüéØ Overall Test Results:\")\n",
        "print(f\"   Total images tested: {len(detection_summary)}\")\n",
        "print(f\"   Total bell peppers detected: {total_detected}\")\n",
        "print(f\"   Average per image: {total_detected/len(detection_summary):.1f}\")\n",
        "\n",
        "if class_totals:\n",
        "    print(f\"   Detected classes:\")\n",
        "    for class_name, count in class_totals.items():\n",
        "        print(f\"     - {class_name}: {count} instances\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 6: Export and Download Your Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create deployment package for your Flask app\n",
        "print(\"üì¶ Creating Deployment Package...\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Create deployment directory\n",
        "deployment_dir = Path('bell_pepper_model_deployment')\n",
        "deployment_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Copy the best model\n",
        "shutil.copy2(best_model_path, deployment_dir / 'bell_pepper_model.pt')\n",
        "print(\"‚úÖ Copied best model: bell_pepper_model.pt\")\n",
        "\n",
        "# Copy training configuration\n",
        "shutil.copy2(latest_run / 'args.yaml', deployment_dir / 'training_config.yaml')\n",
        "print(\"‚úÖ Copied training configuration\")\n",
        "\n",
        "# Copy dataset configuration\n",
        "shutil.copy2(f\"{dataset_path}/dataset.yaml\", deployment_dir / 'dataset_classes.yaml')\n",
        "print(\"‚úÖ Copied dataset classes configuration\")\n",
        "\n",
        "# Create comprehensive model information file\n",
        "model_info = f'''# üå∂Ô∏è Bell Pepper YOLOv8 Detection Model\n",
        "\n",
        "## Model Information\n",
        "- **Model Type**: YOLOv8 Nano (optimized for speed and efficiency)\n",
        "- **Training Date**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "- **Dataset Size**: {config['train_images']} training, {config['val_images']} validation images\n",
        "- **Classes**: {config['nc']} bell pepper varieties\n",
        "- **Image Size**: {TRAINING_CONFIG['img_size']}px\n",
        "- **Epochs Trained**: {TRAINING_CONFIG['epochs']}\n",
        "\n",
        "## Performance Metrics\n",
        "- **mAP@0.5**: {val_results.box.map50:.3f} ({val_results.box.map50*100:.1f}%)\n",
        "- **mAP@0.5:0.95**: {val_results.box.map:.3f} ({val_results.box.map*100:.1f}%)\n",
        "- **Precision**: {val_results.box.mp:.3f} ({val_results.box.mp*100:.1f}%)\n",
        "- **Recall**: {val_results.box.mr:.3f} ({val_results.box.mr*100:.1f}%)\n",
        "- **Model Size**: {model_size_mb:.1f} MB\n",
        "- **Parameters**: {total_params:,}\n",
        "\n",
        "## Classes Detected\n",
        "{chr(10).join([f'- {name}' for name in val_results.names])}\n",
        "\n",
        "## Usage in Python\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your trained model\n",
        "model = YOLO('bell_pepper_model.pt')\n",
        "\n",
        "# Run inference on an image\n",
        "results = model('path/to/bell_pepper_image.jpg')\n",
        "\n",
        "# Process results\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Bounding boxes\n",
        "    for box in boxes:\n",
        "        conf = box.conf.item()  # Confidence score\n",
        "        cls = box.cls.item()    # Class ID\n",
        "        class_name = result.names[int(cls)]  # Class name\n",
        "        print(f\"Detected {{class_name}} with {{conf:.2f}} confidence\")\n",
        "```\n",
        "\n",
        "## Integration with Your Flask App\n",
        "\n",
        "### Step 1: Update Model Loading\n",
        "Replace the model loading in your `app.py`:\n",
        "\n",
        "```python\n",
        "# Replace this line:\n",
        "MODELS = {{\n",
        "    'object_detection': YOLO('yolov8n.pt'),  # General model\n",
        "    # ...\n",
        "}}\n",
        "\n",
        "# With this:\n",
        "MODELS = {{\n",
        "    'bell_pepper_detection': YOLO('models/bell_pepper_model.pt'),  # Your trained model\n",
        "    'ripeness_detection': YOLO('models/bell_pepper_model.pt'),     # Same model for ripeness\n",
        "    'disease_detection': None  # Add disease model later if needed\n",
        "}}\n",
        "```\n",
        "\n",
        "### Step 2: Update Detection Logic\n",
        "In your upload function, change:\n",
        "\n",
        "```python\n",
        "# From:\n",
        "results = MODELS['object_detection'](filepath)\n",
        "\n",
        "# To:\n",
        "results = MODELS['bell_pepper_detection'](filepath)\n",
        "```\n",
        "\n",
        "### Step 3: Update Bell Pepper Detection\n",
        "Your model now automatically detects bell peppers, so update the detection logic:\n",
        "\n",
        "```python\n",
        "# All detections from your model are bell peppers\n",
        "bell_peppers_detected = len(result.boxes) > 0 if result.boxes is not None else False\n",
        "\n",
        "# Each detection will have a specific bell pepper class\n",
        "for box in result.boxes:\n",
        "    cls = int(box.cls.cpu().numpy()[0])\n",
        "    class_name = result.names[cls]  # This will be bell_pepper_1, bell_pepper_2, etc.\n",
        "    conf = float(box.conf.cpu().numpy()[0])\n",
        "    \n",
        "    # Use confidence threshold\n",
        "    if conf > 0.5:  # Adjust this threshold as needed\n",
        "        # Process detected bell pepper\n",
        "        pepper_variety = class_name  # The specific variety/color\n",
        "```\n",
        "\n",
        "## Recommended Confidence Thresholds\n",
        "- **High Precision**: 0.7+ (fewer false positives)\n",
        "- **Balanced**: 0.5 (good balance)\n",
        "- **High Recall**: 0.3+ (catch more peppers, but may have false positives)\n",
        "\n",
        "## Model Performance Analysis\n",
        "- **Best for**: Bell pepper detection and variety classification\n",
        "- **Strengths**: Fast inference, good accuracy on bell peppers\n",
        "- **Use cases**: Quality control, agricultural automation, inventory management\n",
        "\n",
        "## Troubleshooting\n",
        "1. **Low detections**: Lower confidence threshold to 0.3-0.4\n",
        "2. **Too many false positives**: Increase confidence threshold to 0.6-0.7\n",
        "3. **Wrong varieties**: Your model distinguishes 6 varieties - check class mappings\n",
        "4. **Performance issues**: Model is optimized for speed, but ensure GPU is available\n",
        "\n",
        "## Next Steps\n",
        "1. Copy `bell_pepper_model.pt` to your Flask app's `models/` directory\n",
        "2. Update your Flask app using the integration code above\n",
        "3. Test with real bell pepper images\n",
        "4. Fine-tune confidence thresholds based on your specific needs\n",
        "5. Consider collecting more data for classes with lower performance\n",
        "\n",
        "---\n",
        "**Created with ‚ù§Ô∏è using YOLOv8 and the RGBD Pepper Dataset**\n",
        "'''\n",
        "\n",
        "# Write the comprehensive README\n",
        "with open(deployment_dir / 'README.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(model_info)\n",
        "\n",
        "print(\"‚úÖ Created comprehensive model documentation\")\n",
        "\n",
        "# Create a quick integration script\n",
        "integration_script = f'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Quick integration script for Flask app\n",
        "Run this script to automatically update your Flask app\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def integrate_bell_pepper_model():\n",
        "    print(\"üå∂Ô∏è Integrating Bell Pepper Model with Flask App\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check if model file exists\n",
        "    model_file = \"bell_pepper_model.pt\"\n",
        "    if not os.path.exists(model_file):\n",
        "        print(f\"‚ùå Model file not found: {{model_file}}\")\n",
        "        return False\n",
        "    \n",
        "    # Create models directory in Flask app\n",
        "    models_dir = Path(\"../models\")  # Adjust path as needed\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Copy model file\n",
        "    shutil.copy2(model_file, models_dir / model_file)\n",
        "    print(f\"‚úÖ Copied {{model_file}} to {{models_dir}}\")\n",
        "    \n",
        "    print(\"\\\\nüéØ Next Steps:\")\n",
        "    print(\"1. Update your Flask app.py model loading code\")\n",
        "    print(\"2. Test with bell pepper images\")\n",
        "    print(\"3. Adjust confidence thresholds as needed\")\n",
        "    print(\"\\\\nSee README.md for detailed integration instructions!\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    integrate_bell_pepper_model()\n",
        "'''\n",
        "\n",
        "with open(deployment_dir / 'integrate.py', 'w') as f:\n",
        "    f.write(integration_script)\n",
        "\n",
        "print(\"‚úÖ Created integration script\")\n",
        "\n",
        "# List all files in deployment package\n",
        "print(f\"\\\\nüìÅ Deployment Package Contents:\")\n",
        "for file in deployment_dir.glob('*'):\n",
        "    size_mb = file.stat().st_size / (1024 * 1024)\n",
        "    print(f\"   - {{file.name}} ({{size_mb:.1f}} MB)\")\n",
        "\n",
        "print(f\"\\\\nüìä Package Summary:\")\n",
        "print(f\"   Location: {{deployment_dir}}\")\n",
        "print(f\"   Total files: {{len(list(deployment_dir.glob('*')))}}\")\n",
        "print(f\"   Main model: bell_pepper_model.pt ({{model_size_mb:.1f}} MB)\")\n",
        "print(f\"   Ready for production deployment! üöÄ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create downloadable ZIP package\n",
        "import zipfile\n",
        "\n",
        "print(\"üì• Creating Downloadable Package...\")\n",
        "\n",
        "# Create ZIP file with all deployment files\n",
        "zip_filename = 'bell_pepper_yolov8_trained_model'\n",
        "with zipfile.ZipFile(f'{zip_filename}.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for file_path in deployment_dir.glob('*'):\n",
        "        zipf.write(file_path, file_path.name)\n",
        "        print(f\"   Added: {file_path.name}\")\n",
        "\n",
        "print(f\"‚úÖ Created deployment package: {zip_filename}.zip\")\n",
        "\n",
        "# Download the package\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\n‚¨áÔ∏è Downloading your trained bell pepper model...\")\n",
        "files.download(f\"{zip_filename}.zip\")\n",
        "\n",
        "print(\"\\nüéâ SUCCESS! Your Bell Pepper Detection Model is Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"üì¶ Downloaded Package Contains:\")\n",
        "print(\"   ‚Ä¢ bell_pepper_model.pt - Your trained model\")\n",
        "print(\"   ‚Ä¢ README.md - Complete integration guide\")\n",
        "print(\"   ‚Ä¢ integrate.py - Quick integration script\")\n",
        "print(\"   ‚Ä¢ Configuration files\")\n",
        "\n",
        "print(\"\\nüöÄ Next Steps:\")\n",
        "print(\"1. Extract the downloaded ZIP file\")\n",
        "print(\"2. Copy 'bell_pepper_model.pt' to your Flask app's models/ folder\")\n",
        "print(\"3. Follow the integration instructions in README.md\")\n",
        "print(\"4. Test your specialized bell pepper detector!\")\n",
        "\n",
        "print(f\"\\nüìä Your Model Performance:\")\n",
        "print(f\"   ‚Ä¢ mAP@0.5: {val_results.box.map50*100:.1f}% - {performance.split(' - ')[0]}\")\n",
        "print(f\"   ‚Ä¢ Model Size: {model_size_mb:.1f} MB\")\n",
        "print(f\"   ‚Ä¢ Classes: {config['nc']} bell pepper varieties\")\n",
        "print(f\"   ‚Ä¢ Ready for production use! üå∂Ô∏è\")\n",
        "\n",
        "print(\"\\nüí° Tips for Best Results:\")\n",
        "print(\"   ‚Ä¢ Use confidence threshold of 0.5 for balanced results\")\n",
        "print(\"   ‚Ä¢ Lower to 0.3 for higher recall (more detections)\")\n",
        "print(\"   ‚Ä¢ Raise to 0.7 for higher precision (fewer false positives)\")\n",
        "print(\"   ‚Ä¢ Your model now detects specific bell pepper varieties!\")\n",
        "\n",
        "print(\"\\nüéØ Integration Summary:\")\n",
        "print(\"   Your specialized model will significantly outperform\")\n",
        "print(\"   the generic YOLO model for bell pepper detection!\")\n",
        "print(\"   Thank you for using the RGBD Pepper dataset! üì∏üå∂Ô∏è\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
