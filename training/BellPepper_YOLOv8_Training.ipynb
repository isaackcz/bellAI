{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🌶️ Bell Pepper Detection with YOLOv8\n",
        "\n",
        "This notebook trains a specialized YOLOv8 model for bell pepper detection and quality assessment.\n",
        "\n",
        "## 📋 Steps Overview:\n",
        "1. **Setup Environment** - Install dependencies\n",
        "2. **Upload Dataset** - Upload your YOLO dataset\n",
        "3. **Configure Training** - Set training parameters\n",
        "4. **Train Model** - Train YOLOv8 on bell pepper data\n",
        "5. **Validate Results** - Test and evaluate the model\n",
        "6. **Export Model** - Download trained model for production\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Step 1: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install ultralytics\n",
        "%pip install roboflow\n",
        "%pip install wandb  # For experiment tracking (optional)\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected. Training will be slower on CPU.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📁 Step 2: Download Dataset from Google Drive\n",
        "\n",
        "Since you've uploaded your dataset to Google Drive, we'll download it directly to Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset from Google Drive\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Your Google Drive file ID\n",
        "file_id = \"1PZYraaZ4q-G_N0fQz_GXlD8nNvdOoFNJ\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "print(\"📥 Downloading Bell Pepper YOLO Dataset from Google Drive...\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Download the ZIP file\n",
        "gdown.download(url, \"bell_pepper_yolo_dataset.zip\", quiet=False)\n",
        "\n",
        "# Extract the dataset\n",
        "print(\"\\n📂 Extracting dataset...\")\n",
        "with zipfile.ZipFile(\"bell_pepper_yolo_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# Clean up ZIP file\n",
        "os.remove(\"bell_pepper_yolo_dataset.zip\")\n",
        "\n",
        "print(\"✅ Dataset downloaded and extracted successfully!\")\n",
        "\n",
        "# Find the dataset directory (it might be nested)\n",
        "dataset_path = None\n",
        "possible_paths = [\"yolo_dataset\", \"dataset\", \"bell_pepper_dataset\"]\n",
        "\n",
        "# Check current directory for extracted files\n",
        "extracted_items = [item for item in os.listdir(\".\") if os.path.isdir(item)]\n",
        "print(f\"\\n📁 Extracted directories: {extracted_items}\")\n",
        "\n",
        "# Look for the dataset directory\n",
        "for item in extracted_items:\n",
        "    item_path = Path(item)\n",
        "    # Check if this directory contains the expected YOLO structure\n",
        "    if (item_path / \"images\").exists() or (item_path / \"dataset.yaml\").exists():\n",
        "        dataset_path = str(item_path)\n",
        "        print(f\"✅ Found dataset directory: {dataset_path}\")\n",
        "        break\n",
        "\n",
        "# If not found in direct subdirectories, look deeper\n",
        "if dataset_path is None:\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if \"dataset.yaml\" in files:\n",
        "            dataset_path = root\n",
        "            print(f\"✅ Found dataset directory: {dataset_path}\")\n",
        "            break\n",
        "\n",
        "if dataset_path is None:\n",
        "    print(\"❌ Dataset directory not found! Let's explore the structure...\")\n",
        "    # Show all extracted contents\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if root != \".\":  # Skip current directory\n",
        "            level = root.count(os.sep) - 1\n",
        "            indent = \" \" * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = \" \" * 2 * (level + 1)\n",
        "            for file in files[:5]:  # Show first 5 files\n",
        "                print(f\"{subindent}{file}\")\n",
        "            if len(files) > 5:\n",
        "                print(f\"{subindent}... and {len(files) - 5} more files\")\n",
        "else:\n",
        "    # Show the found dataset structure\n",
        "    print(f\"\\n📁 Dataset structure in {dataset_path}:\")\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        level = root.replace(dataset_path, \"\").count(os.sep)\n",
        "        indent = \" \" * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = \" \" * 2 * (level + 1)\n",
        "        for file in files[:3]:  # Show first 3 files\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"{subindent}... and {len(files) - 3} more files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify dataset structure and preview samples\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import yaml\n",
        "\n",
        "def verify_dataset_structure(dataset_path):\n",
        "    \"\"\"Verify the dataset has correct YOLO structure\"\"\"\n",
        "    if dataset_path is None:\n",
        "        print(\"❌ No dataset path provided!\")\n",
        "        return None, False\n",
        "        \n",
        "    dataset_path = Path(dataset_path)\n",
        "    \n",
        "    required_dirs = [\n",
        "        'images/train', 'images/val',\n",
        "        'labels/train', 'labels/val'\n",
        "    ]\n",
        "    \n",
        "    print(\"🔍 Dataset Structure Verification:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    all_good = True\n",
        "    for dir_name in required_dirs:\n",
        "        dir_path = dataset_path / dir_name\n",
        "        if dir_path.exists():\n",
        "            file_count = len(list(dir_path.glob('*')))\n",
        "            print(f\"✅ {dir_name}: {file_count} files\")\n",
        "        else:\n",
        "            print(f\"❌ {dir_name}: Missing!\")\n",
        "            all_good = False\n",
        "    \n",
        "    # Check for dataset.yaml\n",
        "    yaml_path = dataset_path / 'dataset.yaml'\n",
        "    if yaml_path.exists():\n",
        "        print(f\"✅ dataset.yaml: Found\")\n",
        "        \n",
        "        # Load and display dataset config\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config = yaml.safe_load(f)\n",
        "        \n",
        "        print(f\"\\n📊 Dataset Configuration:\")\n",
        "        print(f\"   Classes: {config.get('nc', 'Unknown')}\")\n",
        "        print(f\"   Class names: {config.get('names', 'Unknown')}\")\n",
        "        print(f\"   Train images: {config.get('train_images', 'Unknown')}\")\n",
        "        print(f\"   Val images: {config.get('val_images', 'Unknown')}\")\n",
        "        \n",
        "        return config, all_good\n",
        "        \n",
        "    else:\n",
        "        print(f\"❌ dataset.yaml: Missing!\")\n",
        "        all_good = False\n",
        "    \n",
        "    if all_good:\n",
        "        print(\"\\n🎉 Dataset structure is correct!\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Dataset structure issues detected. Please fix before training.\")\n",
        "    \n",
        "    return None, all_good\n",
        "\n",
        "# Verify the dataset using the found path\n",
        "if 'dataset_path' in locals() and dataset_path is not None:\n",
        "    config, dataset_valid = verify_dataset_structure(dataset_path)\n",
        "else:\n",
        "    print(\"⚠️ Dataset path not found. Please run the previous cell first.\")\n",
        "    config, dataset_valid = None, False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix dataset structure if needed\n",
        "if not dataset_valid and dataset_path is not None:\n",
        "    print(\"🔧 Attempting to fix dataset structure...\")\n",
        "    \n",
        "    # Sometimes the dataset might be in a subdirectory or have different structure\n",
        "    # Let's look for images and labels directories\n",
        "    dataset_root = Path(dataset_path)\n",
        "    \n",
        "    # Find images and labels directories\n",
        "    images_dirs = list(dataset_root.rglob(\"images\"))\n",
        "    labels_dirs = list(dataset_root.rglob(\"labels\"))\n",
        "    yaml_files = list(dataset_root.rglob(\"*.yaml\"))\n",
        "    \n",
        "    print(f\"Found images directories: {[str(d) for d in images_dirs]}\")\n",
        "    print(f\"Found labels directories: {[str(d) for d in labels_dirs]}\")\n",
        "    print(f\"Found YAML files: {[str(f) for f in yaml_files]}\")\n",
        "    \n",
        "    # If we found the structure but it's nested, update the dataset_path\n",
        "    if images_dirs and labels_dirs:\n",
        "        # Find the common parent directory\n",
        "        common_parent = images_dirs[0].parent\n",
        "        if (common_parent / \"images\").exists() and (common_parent / \"labels\").exists():\n",
        "            dataset_path = str(common_parent)\n",
        "            print(f\"🔄 Updated dataset path to: {dataset_path}\")\n",
        "            \n",
        "            # Re-verify with the new path\n",
        "            config, dataset_valid = verify_dataset_structure(dataset_path)\n",
        "    \n",
        "    # If still not valid, try to create a proper structure\n",
        "    if not dataset_valid:\n",
        "        print(\"🔨 Attempting to restructure dataset...\")\n",
        "        \n",
        "        # Create a new properly structured dataset\n",
        "        new_dataset_path = \"bell_pepper_yolo_dataset\"\n",
        "        new_dataset = Path(new_dataset_path)\n",
        "        \n",
        "        # Create directories\n",
        "        (new_dataset / \"images\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "        (new_dataset / \"images\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "        (new_dataset / \"labels\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "        (new_dataset / \"labels\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # If we have any YAML files, copy the first one\n",
        "        if yaml_files:\n",
        "            import shutil\n",
        "            shutil.copy2(yaml_files[0], new_dataset / \"dataset.yaml\")\n",
        "            print(f\"✅ Copied dataset configuration: {yaml_files[0].name}\")\n",
        "        \n",
        "        # Try to move/copy files if we can find them\n",
        "        all_images = list(Path(dataset_path).rglob(\"*.jpg\")) + list(Path(dataset_path).rglob(\"*.png\"))\n",
        "        all_labels = list(Path(dataset_path).rglob(\"*.txt\"))\n",
        "        \n",
        "        if all_images:\n",
        "            print(f\"Found {len(all_images)} image files\")\n",
        "            # For now, put everything in train (you can split later)\n",
        "            train_dir = new_dataset / \"images\" / \"train\"\n",
        "            for img in all_images[:10]:  # Copy first 10 as example\n",
        "                shutil.copy2(img, train_dir / img.name)\n",
        "        \n",
        "        if all_labels and len(all_labels) > 1:  # More than just dataset.yaml\n",
        "            print(f\"Found {len(all_labels)} label files\")\n",
        "            train_labels_dir = new_dataset / \"labels\" / \"train\"\n",
        "            for lbl in all_labels[:10]:  # Copy first 10 as example\n",
        "                if lbl.name != \"dataset.yaml\":\n",
        "                    shutil.copy2(lbl, train_labels_dir / lbl.name)\n",
        "        \n",
        "        # Update dataset path\n",
        "        dataset_path = new_dataset_path\n",
        "        print(f\"🔄 Created new dataset structure at: {dataset_path}\")\n",
        "        \n",
        "        # Re-verify\n",
        "        config, dataset_valid = verify_dataset_structure(dataset_path)\n",
        "\n",
        "if dataset_valid:\n",
        "    print(\"🎉 Dataset is now ready for training!\")\n",
        "else:\n",
        "    print(\"⚠️ Dataset structure still needs manual fixing.\")\n",
        "    print(\"Please check the extracted files and ensure proper YOLO format.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview sample images with annotations\n",
        "def preview_samples(dataset_path, num_samples=4):\n",
        "    \"\"\"Preview sample images with their annotations\"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    \n",
        "    # Get sample images from training set\n",
        "    train_images = list((dataset_path / 'images' / 'train').glob('*'))\n",
        "    sample_images = train_images[:num_samples]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Load class names from config\n",
        "    class_names = config['names'] if config else [f'bell_pepper_{i}' for i in range(6)]\n",
        "    \n",
        "    for i, img_path in enumerate(sample_images):\n",
        "        if i >= 4:\n",
        "            break\n",
        "            \n",
        "        # Load image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        height, width = img.shape[:2]\n",
        "        \n",
        "        # Load corresponding label file\n",
        "        label_path = dataset_path / 'labels' / 'train' / f\"{img_path.stem}.txt\"\n",
        "        \n",
        "        ax = axes[i]\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"Sample {i+1}: {img_path.name}\", fontsize=10)\n",
        "        ax.axis('off')\n",
        "        \n",
        "        # Draw bounding boxes if label file exists\n",
        "        bbox_count = 0\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            \n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id, x_center, y_center, bbox_width, bbox_height = map(float, parts)\n",
        "                    \n",
        "                    # Convert YOLO format to pixel coordinates\n",
        "                    x_center *= width\n",
        "                    y_center *= height\n",
        "                    bbox_width *= width\n",
        "                    bbox_height *= height\n",
        "                    \n",
        "                    # Calculate top-left corner\n",
        "                    x = x_center - bbox_width / 2\n",
        "                    y = y_center - bbox_height / 2\n",
        "                    \n",
        "                    # Draw bounding box\n",
        "                    rect = patches.Rectangle((x, y), bbox_width, bbox_height, \n",
        "                                           linewidth=2, edgecolor='red', facecolor='none')\n",
        "                    ax.add_patch(rect)\n",
        "                    \n",
        "                    # Add class label\n",
        "                    class_name = class_names[int(class_id)] if int(class_id) < len(class_names) else f\"Class {int(class_id)}\"\n",
        "                    ax.text(x, y-5, class_name, color='red', fontsize=8, \n",
        "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "                    bbox_count += 1\n",
        "        \n",
        "        # Add bbox count to title\n",
        "        ax.set_title(f\"Sample {i+1} ({bbox_count} peppers): {img_path.name}\", fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if dataset_valid and config:\n",
        "    print(\"🖼️ Sample Images with Annotations:\")\n",
        "    preview_samples(dataset_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚙️ Step 3: Configure Training Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration optimized for your dataset\n",
        "TRAINING_CONFIG = {\n",
        "    # Model settings - Using nano model for faster training with limited specs\n",
        "    'model_size': 'yolov8n.pt',  # Options: yolov8n.pt, yolov8s.pt, yolov8m.pt\n",
        "    \n",
        "    # Training parameters optimized for your 620 image dataset\n",
        "    'epochs': 150,              # Good for your dataset size\n",
        "    'batch_size': 16,           # Will adjust based on GPU memory\n",
        "    'img_size': 640,            # Standard YOLO input size\n",
        "    'lr': 0.01,                 # Learning rate\n",
        "    'patience': 50,             # Early stopping patience\n",
        "    \n",
        "    # Data augmentation for bell peppers\n",
        "    'augment': True,            # Enable data augmentation\n",
        "    'hsv_h': 0.015,            # HSV-Hue augmentation (good for color varieties)\n",
        "    'hsv_s': 0.7,              # HSV-Saturation augmentation  \n",
        "    'hsv_v': 0.4,              # HSV-Value augmentation\n",
        "    'degrees': 10.0,           # Small rotation (peppers can be oriented differently)\n",
        "    'translate': 0.1,          # Translation\n",
        "    'scale': 0.5,              # Scale variation\n",
        "    'shear': 0.0,              # No shear (keeps pepper shape)\n",
        "    'perspective': 0.0,        # No perspective (keeps pepper shape)\n",
        "    'flipud': 0.0,             # No vertical flip (peppers hang down)\n",
        "    'fliplr': 0.5,             # Horizontal flip (peppers can be on either side)\n",
        "    'mosaic': 1.0,             # Mosaic augmentation (great for detection)\n",
        "    'mixup': 0.0,              # No mixup for better bounding box learning\n",
        "    \n",
        "    # Output settings\n",
        "    'project': 'bell_pepper_training',  # Project name\n",
        "    'name': 'yolov8_bell_pepper_v1',    # Experiment name\n",
        "    'save_period': 25,                  # Save checkpoint every 25 epochs\n",
        "}\n",
        "\n",
        "print(\"🔧 Training Configuration for Bell Pepper Detection:\")\n",
        "print(\"=\" * 55)\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"{key:20}: {value}\")\n",
        "\n",
        "# Adjust batch size based on available GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB\n",
        "    print(f\"\\n💾 GPU Memory: {gpu_memory:.1f} GB\")\n",
        "    \n",
        "    if gpu_memory < 6:\n",
        "        TRAINING_CONFIG['batch_size'] = 8\n",
        "        print(\"⚠️ Reduced batch size to 8 due to limited GPU memory\")\n",
        "    elif gpu_memory < 4:\n",
        "        TRAINING_CONFIG['batch_size'] = 4\n",
        "        print(\"⚠️ Reduced batch size to 4 due to very limited GPU memory\")\n",
        "    elif gpu_memory > 12:\n",
        "        TRAINING_CONFIG['batch_size'] = 32\n",
        "        print(\"🚀 Increased batch size to 32 for better training speed\")\n",
        "else:\n",
        "    TRAINING_CONFIG['batch_size'] = 4\n",
        "    TRAINING_CONFIG['epochs'] = 100\n",
        "    print(\"⚠️ CPU training detected - reduced batch size and epochs\")\n",
        "\n",
        "print(f\"\\n🎯 Final batch size: {TRAINING_CONFIG['batch_size']}\")\n",
        "\n",
        "# Only print dataset info if config is available\n",
        "if config is not None:\n",
        "    print(f\"📊 Dataset: {config.get('train_images', 'Unknown')} train, {config.get('val_images', 'Unknown')} val images\")\n",
        "    print(f\"🏷️ Classes: {config.get('nc', 'Unknown')} bell pepper varieties\")\n",
        "else:\n",
        "    print(\"⚠️ Dataset configuration not loaded. Please verify dataset structure first.\")\n",
        "    print(\"📊 Dataset: Configuration pending...\")\n",
        "    print(\"🏷️ Classes: Will be determined after dataset verification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix dataset.yaml paths before training\n",
        "print(\"🔧 Fixing dataset.yaml paths for training...\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if dataset_path is None:\n",
        "    print(\"❌ Dataset path not found. Please run the previous cells first.\")\n",
        "else:\n",
        "    # Load the current dataset.yaml\n",
        "    yaml_path = Path(dataset_path) / 'dataset.yaml'\n",
        "    \n",
        "    if yaml_path.exists():\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            dataset_config = yaml.safe_load(f)\n",
        "        \n",
        "        # Get absolute path to dataset directory\n",
        "        current_dataset_path = Path(dataset_path).absolute()\n",
        "        \n",
        "        # Create corrected dataset.yaml with absolute paths\n",
        "        corrected_config = {\n",
        "            'path': str(current_dataset_path),  # Dataset root dir (absolute path)\n",
        "            'train': 'images/train',  # Train images (relative to 'path')\n",
        "            'val': 'images/val',      # Val images (relative to 'path')\n",
        "            'nc': dataset_config.get('nc', 6),  # Number of classes\n",
        "            'names': dataset_config.get('names', [f'bell_pepper_{i+1}' for i in range(6)]),  # Class names\n",
        "        }\n",
        "        \n",
        "        # Write corrected dataset.yaml\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(corrected_config, f, default_flow_style=False)\n",
        "        \n",
        "        print(f\"✅ Updated dataset.yaml with correct paths:\")\n",
        "        print(f\"   Path: {corrected_config['path']}\")\n",
        "        print(f\"   Train: {corrected_config['train']}\")\n",
        "        print(f\"   Val: {corrected_config['val']}\")\n",
        "        print(f\"   Classes: {corrected_config['nc']}\")\n",
        "        print(f\"   Names: {corrected_config['names']}\")\n",
        "        \n",
        "        # Verify the paths exist\n",
        "        train_path = current_dataset_path / 'images' / 'train'\n",
        "        val_path = current_dataset_path / 'images' / 'val'\n",
        "        train_labels_path = current_dataset_path / 'labels' / 'train'\n",
        "        val_labels_path = current_dataset_path / 'labels' / 'val'\n",
        "        \n",
        "        train_images = len(list(train_path.glob('*'))) if train_path.exists() else 0\n",
        "        val_images = len(list(val_path.glob('*'))) if val_path.exists() else 0\n",
        "        train_labels = len(list(train_labels_path.glob('*.txt'))) if train_labels_path.exists() else 0\n",
        "        val_labels = len(list(val_labels_path.glob('*.txt'))) if val_labels_path.exists() else 0\n",
        "        \n",
        "        print(f\"\\n📊 Dataset Statistics:\")\n",
        "        print(f\"   Train images: {train_images}\")\n",
        "        print(f\"   Train labels: {train_labels}\")\n",
        "        print(f\"   Val images: {val_images}\")\n",
        "        print(f\"   Val labels: {val_labels}\")\n",
        "        \n",
        "        # Check if paths are valid\n",
        "        if train_images == 0 or val_images == 0:\n",
        "            print(\"\\n⚠️ Warning: Some image directories are empty!\")\n",
        "            print(\"Searching for images in dataset...\")\n",
        "            \n",
        "            # Find all images in the dataset\n",
        "            all_images = list(current_dataset_path.rglob(\"*.jpg\")) + list(current_dataset_path.rglob(\"*.png\"))\n",
        "            all_labels = list(current_dataset_path.rglob(\"*.txt\"))\n",
        "            \n",
        "            print(f\"Total images found: {len(all_images)}\")\n",
        "            print(f\"Total txt files found: {len(all_labels)}\")\n",
        "            \n",
        "            if len(all_images) > 0:\n",
        "                print(\"\\n📁 Image file locations (first 5):\")\n",
        "                for img in all_images[:5]:\n",
        "                    rel_path = img.relative_to(current_dataset_path)\n",
        "                    print(f\"   {rel_path}\")\n",
        "                \n",
        "                # Try to organize files if needed\n",
        "                if train_images == 0 and len(all_images) > 0:\n",
        "                    print(\"\\n🔨 Attempting to organize dataset...\")\n",
        "                    \n",
        "                    # Create directories if they don't exist\n",
        "                    train_path.mkdir(parents=True, exist_ok=True)\n",
        "                    val_path.mkdir(parents=True, exist_ok=True)\n",
        "                    train_labels_path.mkdir(parents=True, exist_ok=True)\n",
        "                    val_labels_path.mkdir(parents=True, exist_ok=True)\n",
        "                    \n",
        "                    # Move images to train/val (80/20 split)\n",
        "                    import shutil\n",
        "                    import random\n",
        "                    \n",
        "                    random.shuffle(all_images)\n",
        "                    split_idx = int(0.8 * len(all_images))\n",
        "                    \n",
        "                    train_imgs = all_images[:split_idx]\n",
        "                    val_imgs = all_images[split_idx:]\n",
        "                    \n",
        "                    # Copy images\n",
        "                    for img in train_imgs:\n",
        "                        shutil.copy2(img, train_path / img.name)\n",
        "                    \n",
        "                    for img in val_imgs:\n",
        "                        shutil.copy2(img, val_path / img.name)\n",
        "                    \n",
        "                    # Copy corresponding labels\n",
        "                    for img in train_imgs:\n",
        "                        label_name = img.stem + '.txt'\n",
        "                        for label_file in all_labels:\n",
        "                            if label_file.name == label_name:\n",
        "                                shutil.copy2(label_file, train_labels_path / label_name)\n",
        "                                break\n",
        "                    \n",
        "                    for img in val_imgs:\n",
        "                        label_name = img.stem + '.txt'\n",
        "                        for label_file in all_labels:\n",
        "                            if label_file.name == label_name:\n",
        "                                shutil.copy2(label_file, val_labels_path / label_name)\n",
        "                                break\n",
        "                    \n",
        "                    print(f\"✅ Organized dataset:\")\n",
        "                    print(f\"   Moved {len(train_imgs)} images to train\")\n",
        "                    print(f\"   Moved {len(val_imgs)} images to val\")\n",
        "        \n",
        "        print(f\"\\n🎯 Dataset ready for training!\")\n",
        "        print(f\"📄 Using dataset config: {yaml_path}\")\n",
        "        \n",
        "    else:\n",
        "        print(f\"❌ dataset.yaml not found at {yaml_path}\")\n",
        "        print(\"Creating a basic dataset.yaml file...\")\n",
        "        \n",
        "        # Create a basic dataset.yaml\n",
        "        basic_config = {\n",
        "            'path': str(Path(dataset_path).absolute()),\n",
        "            'train': 'images/train',\n",
        "            'val': 'images/val',\n",
        "            'nc': 6,\n",
        "            'names': [f'bell_pepper_{i+1}' for i in range(6)]\n",
        "        }\n",
        "        \n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(basic_config, f, default_flow_style=False)\n",
        "        \n",
        "        print(f\"✅ Created basic dataset.yaml at {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Step 4: Train the Bell Pepper Detection Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the bell pepper detection model\n",
        "print(\"🚀 Starting Bell Pepper YOLOv8 Training...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load the base model\n",
        "model = YOLO(TRAINING_CONFIG['model_size'])\n",
        "\n",
        "# Print model info\n",
        "print(f\"📱 Model: {TRAINING_CONFIG['model_size']}\")\n",
        "print(f\"🔢 Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
        "print(f\"📊 Dataset: {config['nc']} classes, {config['train_images']} train images\")\n",
        "print(f\"⚙️ Batch size: {TRAINING_CONFIG['batch_size']}, Epochs: {TRAINING_CONFIG['epochs']}\")\n",
        "\n",
        "print(\"\\n🎬 Starting training process...\")\n",
        "print(\"This may take 30-60 minutes depending on your GPU...\")\n",
        "\n",
        "# Start training with optimized settings for bell peppers\n",
        "results = model.train(\n",
        "    data=f\"{dataset_path}/dataset.yaml\",\n",
        "    epochs=TRAINING_CONFIG['epochs'],\n",
        "    batch=TRAINING_CONFIG['batch_size'],\n",
        "    imgsz=TRAINING_CONFIG['img_size'],\n",
        "    lr0=TRAINING_CONFIG['lr'],\n",
        "    patience=TRAINING_CONFIG['patience'],\n",
        "    \n",
        "    # Data augmentation optimized for bell peppers\n",
        "    augment=TRAINING_CONFIG['augment'],\n",
        "    hsv_h=TRAINING_CONFIG['hsv_h'],\n",
        "    hsv_s=TRAINING_CONFIG['hsv_s'],\n",
        "    hsv_v=TRAINING_CONFIG['hsv_v'],\n",
        "    degrees=TRAINING_CONFIG['degrees'],\n",
        "    translate=TRAINING_CONFIG['translate'],\n",
        "    scale=TRAINING_CONFIG['scale'],\n",
        "    shear=TRAINING_CONFIG['shear'],\n",
        "    perspective=TRAINING_CONFIG['perspective'],\n",
        "    flipud=TRAINING_CONFIG['flipud'],\n",
        "    fliplr=TRAINING_CONFIG['fliplr'],\n",
        "    mosaic=TRAINING_CONFIG['mosaic'],\n",
        "    mixup=TRAINING_CONFIG['mixup'],\n",
        "    \n",
        "    # Output settings\n",
        "    project=TRAINING_CONFIG['project'],\n",
        "    name=TRAINING_CONFIG['name'],\n",
        "    save_period=TRAINING_CONFIG['save_period'],\n",
        "    \n",
        "    # Additional settings for optimal training\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    workers=4,\n",
        "    verbose=True,\n",
        "    seed=42,  # For reproducible results\n",
        "    optimizer='AdamW',  # Good optimizer for small datasets\n",
        "    close_mosaic=10,    # Disable mosaic in last 10 epochs for better accuracy\n",
        ")\n",
        "\n",
        "print(\"\\n🎉 Training completed successfully!\")\n",
        "print(\"📁 Training results and model weights have been saved.\")\n",
        "\n",
        "# Display training summary\n",
        "if hasattr(results, 'results_dict'):\n",
        "    print(f\"\\n📊 Final Training Metrics:\")\n",
        "    metrics = results.results_dict\n",
        "    if 'metrics/mAP50(B)' in metrics:\n",
        "        print(f\"   mAP@0.5: {metrics['metrics/mAP50(B)']:.3f}\")\n",
        "    if 'metrics/mAP50-95(B)' in metrics:\n",
        "        print(f\"   mAP@0.5:0.95: {metrics['metrics/mAP50-95(B)']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Step 5: Analyze Training Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find and display training results\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "\n",
        "# Find the latest training run directory\n",
        "project_dir = Path(TRAINING_CONFIG['project'])\n",
        "latest_run = max(project_dir.glob(f\"{TRAINING_CONFIG['name']}*\"), key=os.path.getctime)\n",
        "\n",
        "print(f\"📁 Training results saved in: {latest_run}\")\n",
        "print(f\"🎯 Model files location: {latest_run}/weights/\")\n",
        "\n",
        "# Display training curves\n",
        "results_img = latest_run / 'results.png'\n",
        "if results_img.exists():\n",
        "    print(\"\\n📈 Training Results and Loss Curves:\")\n",
        "    display(Image(str(results_img), width=800))\n",
        "else:\n",
        "    print(\"⚠️ Results image not found\")\n",
        "\n",
        "# Display confusion matrix\n",
        "confusion_matrix = latest_run / 'confusion_matrix.png'\n",
        "if confusion_matrix.exists():\n",
        "    print(\"\\n🔍 Confusion Matrix:\")\n",
        "    display(Image(str(confusion_matrix), width=600))\n",
        "else:\n",
        "    print(\"⚠️ Confusion matrix not found\")\n",
        "\n",
        "# Display F1 confidence curve\n",
        "f1_curve = latest_run / 'F1_curve.png'\n",
        "if f1_curve.exists():\n",
        "    print(\"\\n📊 F1-Confidence Curve:\")\n",
        "    display(Image(str(f1_curve), width=600))\n",
        "\n",
        "# Display precision-recall curve\n",
        "pr_curve = latest_run / 'PR_curve.png'\n",
        "if pr_curve.exists():\n",
        "    print(\"\\n📊 Precision-Recall Curve:\")\n",
        "    display(Image(str(pr_curve), width=600))\n",
        "\n",
        "# Display validation batch predictions\n",
        "val_batch = latest_run / 'val_batch0_pred.jpg'\n",
        "if val_batch.exists():\n",
        "    print(\"\\n🎯 Model Predictions on Validation Images:\")\n",
        "    display(Image(str(val_batch), width=800))\n",
        "else:\n",
        "    print(\"⚠️ Validation predictions not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the trained model and evaluate performance\n",
        "import random\n",
        "\n",
        "# Load the best trained model\n",
        "best_model_path = latest_run / 'weights' / 'best.pt'\n",
        "trained_model = YOLO(str(best_model_path))\n",
        "\n",
        "print(f\"🧠 Loaded best trained model: {best_model_path}\")\n",
        "\n",
        "# Validate the model on the validation set\n",
        "print(\"\\n📊 Running Model Validation...\")\n",
        "val_results = trained_model.val(data=f\"{dataset_path}/dataset.yaml\")\n",
        "\n",
        "# Print detailed performance metrics\n",
        "print(f\"\\n🎯 Bell Pepper Detection Performance:\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"mAP@0.5     : {val_results.box.map50:.3f} ({val_results.box.map50*100:.1f}%)\")\n",
        "print(f\"mAP@0.5:0.95: {val_results.box.map:.3f} ({val_results.box.map*100:.1f}%)\")\n",
        "print(f\"Precision   : {val_results.box.mp:.3f} ({val_results.box.mp*100:.1f}%)\")\n",
        "print(f\"Recall      : {val_results.box.mr:.3f} ({val_results.box.mr*100:.1f}%)\")\n",
        "\n",
        "# Performance interpretation\n",
        "map50 = val_results.box.map50\n",
        "if map50 > 0.9:\n",
        "    performance = \"🌟 Excellent - Ready for production!\"\n",
        "    recommendation = \"Your model is performing exceptionally well!\"\n",
        "elif map50 > 0.8:\n",
        "    performance = \"🎉 Very Good - Great for most applications\"\n",
        "    recommendation = \"Excellent results! Consider testing on real-world data.\"\n",
        "elif map50 > 0.7:\n",
        "    performance = \"👍 Good - Suitable for many use cases\"\n",
        "    recommendation = \"Good performance. Fine-tune confidence threshold as needed.\"\n",
        "elif map50 > 0.6:\n",
        "    performance = \"⚠️ Fair - May need improvement\"\n",
        "    recommendation = \"Consider training longer or adding more diverse data.\"\n",
        "else:\n",
        "    performance = \"❌ Needs Improvement\"\n",
        "    recommendation = \"Try training with more epochs, better data, or larger model.\"\n",
        "\n",
        "print(f\"\\nOverall Performance: {performance}\")\n",
        "print(f\"Recommendation: {recommendation}\")\n",
        "\n",
        "# Calculate additional metrics\n",
        "total_params = sum(p.numel() for p in trained_model.model.parameters())\n",
        "model_size_mb = os.path.getsize(best_model_path) / (1024 * 1024)\n",
        "\n",
        "print(f\"\\n📱 Model Specifications:\")\n",
        "print(f\"   Parameters: {total_params:,}\")\n",
        "print(f\"   Model size: {model_size_mb:.1f} MB\")\n",
        "print(f\"   Classes: {val_results.names}\")\n",
        "\n",
        "# Class-wise performance if available\n",
        "if hasattr(val_results.box, 'ap_class_index') and val_results.box.ap_class_index is not None:\n",
        "    print(f\"\\n📊 Per-Class Performance (mAP@0.5):\")\n",
        "    for i, class_name in enumerate(val_results.names):\n",
        "        if i < len(val_results.box.ap):\n",
        "            class_map = val_results.box.ap[i].mean()  # Average across IoU thresholds\n",
        "            print(f\"   {class_name}: {class_map:.3f} ({class_map*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test model on sample validation images\n",
        "val_images = list((Path(dataset_path) / 'images' / 'val').glob('*'))\n",
        "test_images = random.sample(val_images, min(6, len(val_images)))\n",
        "\n",
        "print(\"🔮 Model Predictions on Sample Validation Images:\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "detection_summary = []\n",
        "\n",
        "for i, img_path in enumerate(test_images):\n",
        "    if i >= 6:\n",
        "        break\n",
        "    \n",
        "    # Run inference\n",
        "    results = trained_model(str(img_path), conf=0.25)  # Lower confidence for more detections\n",
        "    result = results[0]\n",
        "    \n",
        "    # Plot the result\n",
        "    annotated_img = result.plot()\n",
        "    \n",
        "    ax = axes[i]\n",
        "    ax.imshow(annotated_img)\n",
        "    ax.set_title(f\"Test {i+1}: {img_path.name}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # Count detections by class\n",
        "    detections_count = {}\n",
        "    if result.boxes is not None:\n",
        "        for box in result.boxes:\n",
        "            conf = float(box.conf.cpu().numpy()[0])\n",
        "            cls = int(box.cls.cpu().numpy()[0])\n",
        "            class_name = result.names[cls]\n",
        "            \n",
        "            if class_name not in detections_count:\n",
        "                detections_count[class_name] = 0\n",
        "            detections_count[class_name] += 1\n",
        "        \n",
        "        detection_summary.append({\n",
        "            'image': img_path.name,\n",
        "            'total_detections': len(result.boxes),\n",
        "            'detections': detections_count\n",
        "        })\n",
        "        \n",
        "        # Add detection count to title\n",
        "        total_dets = len(result.boxes)\n",
        "        ax.set_title(f\"Test {i+1} ({total_dets} peppers): {img_path.name}\", fontsize=10)\n",
        "    else:\n",
        "        detection_summary.append({\n",
        "            'image': img_path.name,\n",
        "            'total_detections': 0,\n",
        "            'detections': {}\n",
        "        })\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detection summary\n",
        "print(\"\\n📋 Detection Summary:\")\n",
        "total_detected = 0\n",
        "class_totals = {}\n",
        "\n",
        "for summary in detection_summary:\n",
        "    img_name = summary['image']\n",
        "    total_dets = summary['total_detections']\n",
        "    total_detected += total_dets\n",
        "    \n",
        "    print(f\"\\n📸 {img_name}: {total_dets} bell pepper(s) detected\")\n",
        "    \n",
        "    for class_name, count in summary['detections'].items():\n",
        "        print(f\"   - {class_name}: {count}\")\n",
        "        if class_name not in class_totals:\n",
        "            class_totals[class_name] = 0\n",
        "        class_totals[class_name] += count\n",
        "\n",
        "print(f\"\\n🎯 Overall Test Results:\")\n",
        "print(f\"   Total images tested: {len(detection_summary)}\")\n",
        "print(f\"   Total bell peppers detected: {total_detected}\")\n",
        "print(f\"   Average per image: {total_detected/len(detection_summary):.1f}\")\n",
        "\n",
        "if class_totals:\n",
        "    print(f\"   Detected classes:\")\n",
        "    for class_name, count in class_totals.items():\n",
        "        print(f\"     - {class_name}: {count} instances\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📦 Step 6: Export and Download Your Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create deployment package for your Flask app\n",
        "print(\"📦 Creating Deployment Package...\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Create deployment directory\n",
        "deployment_dir = Path('bell_pepper_model_deployment')\n",
        "deployment_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Copy the best model\n",
        "shutil.copy2(best_model_path, deployment_dir / 'bell_pepper_model.pt')\n",
        "print(\"✅ Copied best model: bell_pepper_model.pt\")\n",
        "\n",
        "# Copy training configuration\n",
        "shutil.copy2(latest_run / 'args.yaml', deployment_dir / 'training_config.yaml')\n",
        "print(\"✅ Copied training configuration\")\n",
        "\n",
        "# Copy dataset configuration\n",
        "shutil.copy2(f\"{dataset_path}/dataset.yaml\", deployment_dir / 'dataset_classes.yaml')\n",
        "print(\"✅ Copied dataset classes configuration\")\n",
        "\n",
        "# Create comprehensive model information file\n",
        "model_info = f'''# 🌶️ Bell Pepper YOLOv8 Detection Model\n",
        "\n",
        "## Model Information\n",
        "- **Model Type**: YOLOv8 Nano (optimized for speed and efficiency)\n",
        "- **Training Date**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "- **Dataset Size**: {config['train_images']} training, {config['val_images']} validation images\n",
        "- **Classes**: {config['nc']} bell pepper varieties\n",
        "- **Image Size**: {TRAINING_CONFIG['img_size']}px\n",
        "- **Epochs Trained**: {TRAINING_CONFIG['epochs']}\n",
        "\n",
        "## Performance Metrics\n",
        "- **mAP@0.5**: {val_results.box.map50:.3f} ({val_results.box.map50*100:.1f}%)\n",
        "- **mAP@0.5:0.95**: {val_results.box.map:.3f} ({val_results.box.map*100:.1f}%)\n",
        "- **Precision**: {val_results.box.mp:.3f} ({val_results.box.mp*100:.1f}%)\n",
        "- **Recall**: {val_results.box.mr:.3f} ({val_results.box.mr*100:.1f}%)\n",
        "- **Model Size**: {model_size_mb:.1f} MB\n",
        "- **Parameters**: {total_params:,}\n",
        "\n",
        "## Classes Detected\n",
        "{chr(10).join([f'- {name}' for name in val_results.names])}\n",
        "\n",
        "## Usage in Python\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your trained model\n",
        "model = YOLO('bell_pepper_model.pt')\n",
        "\n",
        "# Run inference on an image\n",
        "results = model('path/to/bell_pepper_image.jpg')\n",
        "\n",
        "# Process results\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Bounding boxes\n",
        "    for box in boxes:\n",
        "        conf = box.conf.item()  # Confidence score\n",
        "        cls = box.cls.item()    # Class ID\n",
        "        class_name = result.names[int(cls)]  # Class name\n",
        "        print(f\"Detected {{class_name}} with {{conf:.2f}} confidence\")\n",
        "```\n",
        "\n",
        "## Integration with Your Flask App\n",
        "\n",
        "### Step 1: Update Model Loading\n",
        "Replace the model loading in your `app.py`:\n",
        "\n",
        "```python\n",
        "# Replace this line:\n",
        "MODELS = {{\n",
        "    'object_detection': YOLO('yolov8n.pt'),  # General model\n",
        "    # ...\n",
        "}}\n",
        "\n",
        "# With this:\n",
        "MODELS = {{\n",
        "    'bell_pepper_detection': YOLO('models/bell_pepper_model.pt'),  # Your trained model\n",
        "    'ripeness_detection': YOLO('models/bell_pepper_model.pt'),     # Same model for ripeness\n",
        "    'disease_detection': None  # Add disease model later if needed\n",
        "}}\n",
        "```\n",
        "\n",
        "### Step 2: Update Detection Logic\n",
        "In your upload function, change:\n",
        "\n",
        "```python\n",
        "# From:\n",
        "results = MODELS['object_detection'](filepath)\n",
        "\n",
        "# To:\n",
        "results = MODELS['bell_pepper_detection'](filepath)\n",
        "```\n",
        "\n",
        "### Step 3: Update Bell Pepper Detection\n",
        "Your model now automatically detects bell peppers, so update the detection logic:\n",
        "\n",
        "```python\n",
        "# All detections from your model are bell peppers\n",
        "bell_peppers_detected = len(result.boxes) > 0 if result.boxes is not None else False\n",
        "\n",
        "# Each detection will have a specific bell pepper class\n",
        "for box in result.boxes:\n",
        "    cls = int(box.cls.cpu().numpy()[0])\n",
        "    class_name = result.names[cls]  # This will be bell_pepper_1, bell_pepper_2, etc.\n",
        "    conf = float(box.conf.cpu().numpy()[0])\n",
        "    \n",
        "    # Use confidence threshold\n",
        "    if conf > 0.5:  # Adjust this threshold as needed\n",
        "        # Process detected bell pepper\n",
        "        pepper_variety = class_name  # The specific variety/color\n",
        "```\n",
        "\n",
        "## Recommended Confidence Thresholds\n",
        "- **High Precision**: 0.7+ (fewer false positives)\n",
        "- **Balanced**: 0.5 (good balance)\n",
        "- **High Recall**: 0.3+ (catch more peppers, but may have false positives)\n",
        "\n",
        "## Model Performance Analysis\n",
        "- **Best for**: Bell pepper detection and variety classification\n",
        "- **Strengths**: Fast inference, good accuracy on bell peppers\n",
        "- **Use cases**: Quality control, agricultural automation, inventory management\n",
        "\n",
        "## Troubleshooting\n",
        "1. **Low detections**: Lower confidence threshold to 0.3-0.4\n",
        "2. **Too many false positives**: Increase confidence threshold to 0.6-0.7\n",
        "3. **Wrong varieties**: Your model distinguishes 6 varieties - check class mappings\n",
        "4. **Performance issues**: Model is optimized for speed, but ensure GPU is available\n",
        "\n",
        "## Next Steps\n",
        "1. Copy `bell_pepper_model.pt` to your Flask app's `models/` directory\n",
        "2. Update your Flask app using the integration code above\n",
        "3. Test with real bell pepper images\n",
        "4. Fine-tune confidence thresholds based on your specific needs\n",
        "5. Consider collecting more data for classes with lower performance\n",
        "\n",
        "---\n",
        "**Created with ❤️ using YOLOv8 and the RGBD Pepper Dataset**\n",
        "'''\n",
        "\n",
        "# Write the comprehensive README\n",
        "with open(deployment_dir / 'README.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(model_info)\n",
        "\n",
        "print(\"✅ Created comprehensive model documentation\")\n",
        "\n",
        "# Create a quick integration script\n",
        "integration_script = f'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Quick integration script for Flask app\n",
        "Run this script to automatically update your Flask app\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def integrate_bell_pepper_model():\n",
        "    print(\"🌶️ Integrating Bell Pepper Model with Flask App\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check if model file exists\n",
        "    model_file = \"bell_pepper_model.pt\"\n",
        "    if not os.path.exists(model_file):\n",
        "        print(f\"❌ Model file not found: {{model_file}}\")\n",
        "        return False\n",
        "    \n",
        "    # Create models directory in Flask app\n",
        "    models_dir = Path(\"../models\")  # Adjust path as needed\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Copy model file\n",
        "    shutil.copy2(model_file, models_dir / model_file)\n",
        "    print(f\"✅ Copied {{model_file}} to {{models_dir}}\")\n",
        "    \n",
        "    print(\"\\\\n🎯 Next Steps:\")\n",
        "    print(\"1. Update your Flask app.py model loading code\")\n",
        "    print(\"2. Test with bell pepper images\")\n",
        "    print(\"3. Adjust confidence thresholds as needed\")\n",
        "    print(\"\\\\nSee README.md for detailed integration instructions!\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    integrate_bell_pepper_model()\n",
        "'''\n",
        "\n",
        "with open(deployment_dir / 'integrate.py', 'w') as f:\n",
        "    f.write(integration_script)\n",
        "\n",
        "print(\"✅ Created integration script\")\n",
        "\n",
        "# List all files in deployment package\n",
        "print(f\"\\\\n📁 Deployment Package Contents:\")\n",
        "for file in deployment_dir.glob('*'):\n",
        "    size_mb = file.stat().st_size / (1024 * 1024)\n",
        "    print(f\"   - {{file.name}} ({{size_mb:.1f}} MB)\")\n",
        "\n",
        "print(f\"\\\\n📊 Package Summary:\")\n",
        "print(f\"   Location: {{deployment_dir}}\")\n",
        "print(f\"   Total files: {{len(list(deployment_dir.glob('*')))}}\")\n",
        "print(f\"   Main model: bell_pepper_model.pt ({{model_size_mb:.1f}} MB)\")\n",
        "print(f\"   Ready for production deployment! 🚀\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create downloadable ZIP package\n",
        "import zipfile\n",
        "\n",
        "print(\"📥 Creating Downloadable Package...\")\n",
        "\n",
        "# Create ZIP file with all deployment files\n",
        "zip_filename = 'bell_pepper_yolov8_trained_model'\n",
        "with zipfile.ZipFile(f'{zip_filename}.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for file_path in deployment_dir.glob('*'):\n",
        "        zipf.write(file_path, file_path.name)\n",
        "        print(f\"   Added: {file_path.name}\")\n",
        "\n",
        "print(f\"✅ Created deployment package: {zip_filename}.zip\")\n",
        "\n",
        "# Download the package\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\n⬇️ Downloading your trained bell pepper model...\")\n",
        "files.download(f\"{zip_filename}.zip\")\n",
        "\n",
        "print(\"\\n🎉 SUCCESS! Your Bell Pepper Detection Model is Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"📦 Downloaded Package Contains:\")\n",
        "print(\"   • bell_pepper_model.pt - Your trained model\")\n",
        "print(\"   • README.md - Complete integration guide\")\n",
        "print(\"   • integrate.py - Quick integration script\")\n",
        "print(\"   • Configuration files\")\n",
        "\n",
        "print(\"\\n🚀 Next Steps:\")\n",
        "print(\"1. Extract the downloaded ZIP file\")\n",
        "print(\"2. Copy 'bell_pepper_model.pt' to your Flask app's models/ folder\")\n",
        "print(\"3. Follow the integration instructions in README.md\")\n",
        "print(\"4. Test your specialized bell pepper detector!\")\n",
        "\n",
        "print(f\"\\n📊 Your Model Performance:\")\n",
        "print(f\"   • mAP@0.5: {val_results.box.map50*100:.1f}% - {performance.split(' - ')[0]}\")\n",
        "print(f\"   • Model Size: {model_size_mb:.1f} MB\")\n",
        "print(f\"   • Classes: {config['nc']} bell pepper varieties\")\n",
        "print(f\"   • Ready for production use! 🌶️\")\n",
        "\n",
        "print(\"\\n💡 Tips for Best Results:\")\n",
        "print(\"   • Use confidence threshold of 0.5 for balanced results\")\n",
        "print(\"   • Lower to 0.3 for higher recall (more detections)\")\n",
        "print(\"   • Raise to 0.7 for higher precision (fewer false positives)\")\n",
        "print(\"   • Your model now detects specific bell pepper varieties!\")\n",
        "\n",
        "print(\"\\n🎯 Integration Summary:\")\n",
        "print(\"   Your specialized model will significantly outperform\")\n",
        "print(\"   the generic YOLO model for bell pepper detection!\")\n",
        "print(\"   Thank you for using the RGBD Pepper dataset! 📸🌶️\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
